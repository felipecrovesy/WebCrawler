<div align="center">
  <h1 align="center">WebCrawler</h1>

   <div align="center">
     √â um programa de computador que navega pela internet de forma automatizada, coletando informa√ß√µes de p√°ginas da web.
    </div>
</div>

## üìã <a name="table">Sumary</a>

1. ü§ñ [Introdu√ß√£o](#introduction)
2. ‚öôÔ∏è [Tech Stack](#tech-stack)
3. ü§∏ [Como usar](#quick-start)
7. ü§ù [Contribui√ß√µes](#contributing)
8. üë• [Autores](#authors)
<br>

## <a name="introduction">ü§ñ Introdu√ß√£o</a>

Come√ßo da jornada: Um web crawler inicia sua jornada a partir de uma lista de URLs, que s√£o os endere√ßos das p√°ginas da web.

Seguindo os links: Ele acessa essas p√°ginas e identifica todos os links presentes nelas.

Explora√ß√£o cont√≠nua: Em seguida, o crawler segue esses links, explorando novas p√°ginas e repetindo o processo.

Coleta de informa√ß√µes: Ao visitar cada p√°gina, o web crawler extrai informa√ß√µes relevantes, como texto, imagens, v√≠deos e outros tipos de conte√∫do.

Indexa√ß√£o dos dados: As informa√ß√µes coletadas s√£o organizadas e armazenadas em um banco de dados, formando um √≠ndice que facilita a busca e o acesso aos dados.

<br>

**Para que servem os web crawlers**:
___
+ Mecanismos de busca: Os mecanismos de busca, como o Google, utilizam web crawlers para indexar a internet e construir seus √≠ndices de pesquisa.
+ Monitoramento de sites: Web crawlers podem ser usados para monitorar sites em busca de altera√ß√µes, como novas publica√ß√µes ou atualiza√ß√µes de conte√∫do.
+ Coleta de dados: Empresas e pesquisadores podem utilizar web crawlers para coletar dados da web para an√°lise, estudos de mercado e outras finalidades.
+ Compara√ß√£o de pre√ßos: Sites de compara√ß√£o de pre√ßos utilizam web crawlers para coletar informa√ß√µes sobre produtos e pre√ßos em diferentes lojas online.


<br>

**Outros nomes para Webcrawler**:
____
+ Crawler
+ Spider
+ Bot
+ Web robot
+ Indexador autom√°tico

  <br>

## <a name="tech-stack">‚öôÔ∏è Tech Stack</a>

- dotnet 9.0
- Sqlite
  
<br>

## <a name="quick-start">ü§∏ Como usar</a>

Para iniciar o projeto, siga os seguintes passos em seu dispositivo:

**00 - Pr√©-requisitos**

Para usar este projeto voc√™ deve ter instalado previamente os seguintes pacotes:

- [Git](https://git-scm.com/)
- [dotnet 9.0](https://dotnet.microsoft.com/pt-br/download/dotnet/9.0)
- [Chromium](https://www.chromium.org/getting-involved/download-chromium/)
- [Sqlite](https://www.sqlite.org/download.html) (opcional para visualizar a tabela)
  <br/><br/>

**01 - Clonar o Reposit√≥rio**

```bash
git clone https://github.com/felipecrovesy/WebCrawler.git
```

**02 - Rodar o Projeto**

```bash
dotnet run WebCrawler.Presentation
```
Os inputs ficam salvos em ```./WebCrawler/WebCrawler.Presentation/bin/Debug/net9.0```

**03 - Rodar os Tests**

Acesse WebCrawler.UnitTest via terminal

```bash
dotnet test
```
<br>

## <a name="contributing">ü§ù Contribui√ß√µes</a>

Contrigui√ß√µes, issues, e novos recursos s√£o vem vindos!

1. Fa√ßa um Fork do projeto (<https://github.com/yourname/yourproject/fork>)
2. Crie a sua branch de feature (`git checkout -b feature/fooBar`)
3. Commit suas altera√ß√µes (`git commit -am 'Add some fooBar'`)
4. Fa√ßa um Push para a branch (`git push origin feature/fooBar`)
5. Crie um novo Pull Request


## <a name="authors">üë• Autores</a>

<table style="border-collapse: collapse; table-layout: auto; text-align: left;">

  <tbody>
    <tr>
      <td style="padding: 10px; border: 1px solid #ddd;">
        <img src="https://avatars.githubusercontent.com/u/60819196?v=4" width="60" style="border-radius: 50%; display: block; margin: 0 auto;">
      </td>
      <td style="padding: 10px; border: 1px solid #ddd;">Felipe Crovesy</td>
      <td style="padding: 10px; border: 1px solid #ddd;">
        <a href="https://www.linkedin.com/in/felipe-crovesy-6a299283/" target="_blank">LinkedIn</a> |
        <a href="https://github.com/felipecrovesy" target="_blank">GitHub</a>
      </td>
    </tr>
  </tbody>
</table>
